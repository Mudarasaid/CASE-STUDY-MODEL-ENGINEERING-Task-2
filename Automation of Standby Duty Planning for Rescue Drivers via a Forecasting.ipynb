{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pmdarima in c:\\users\\mouda\\anaconda3\\lib\\site-packages (2.0.4)\n",
      "Requirement already satisfied: Cython!=0.29.18,!=0.29.31,>=0.29 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (0.29.13)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (41.4.0)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (23.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (0.13.2)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (0.13.5)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (1.24.2)\n",
      "Requirement already satisfied: pandas>=0.19 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (1.3.5)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (1.21.6)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pmdarima) (1.0.2)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pandas>=0.19->pmdarima) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from pandas>=0.19->pmdarima) (2.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from scikit-learn>=0.22->pmdarima) (3.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\mouda\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.12.0)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sickness_table.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2e3a126b4ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m#read CSV file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sickness_table.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#set the date as index and converting it to datetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sickness_table.csv'"
     ]
    }
   ],
   "source": [
    "#Instaling the needed libraries \n",
    "\n",
    "!pip install pmdarima\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet.plot import plot_plotly, plot_components_plotly\n",
    "from fbprophet import Prophet\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "from pmdarima import auto_arima\n",
    "import warnings \n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\"\"\"\n",
    "Create time series features based on time series index.\n",
    "\"\"\"\n",
    "\n",
    "def create_features(df):\n",
    "   \n",
    "    df = df.copy()\n",
    "    df['hour'] = df.index.hour\n",
    "    df['dayofweek'] = df.index.dayofweek\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    df['dayofyear'] = df.index.dayofyear\n",
    "    df['dayofmonth'] = df.index.day\n",
    "    df['weekofyear'] = df.index.isocalendar().week.astype(int)\n",
    "    return df\n",
    "\n",
    "'''\n",
    "Reading and Data preparation  \n",
    "'''\n",
    "\n",
    "#read CSV file\n",
    "df = pd.read_csv('sickness_table.csv')\n",
    "\n",
    "#set the date as index and converting it to datetime \n",
    "df = df.set_index('date')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "\n",
    "#dropping empty column \n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "#calculating sickness rate\n",
    "df['sickness rate']= df['n_sick']/df['n_duty']\n",
    "\n",
    "#calculating average hundling per call (AHC) and (AHC_target) after concedring dafted\n",
    "df['AHC']=df['calls']/ (df['n_duty']+df['n_sby']-df['n_sick'])\n",
    "df['AHC_target']=df['calls']/ (df['n_duty']+df['n_sby']+df['dafted']-df['n_sick'])\n",
    "df\n",
    "\n",
    "\n",
    "'''\n",
    "Cumpute and visualizing Correlation Matrix \"heat map\"\n",
    "'''\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = df.corr()\n",
    "\n",
    "# Set up the matplotlib figure with gray background\n",
    "plt.figure(figsize=(10, 8), facecolor='lightgray')\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
    "\n",
    "# Add title\n",
    "plt.title('Correlation Matrix')\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    " \n",
    "    \n",
    "    \n",
    "'''\n",
    " visualizing data distribution\n",
    "'''\n",
    "\n",
    "# Define the number of rows and columns for subplots\n",
    "num_rows = 3\n",
    "num_cols = 3\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 12))\n",
    "\n",
    "# Flatten the axes array to easily iterate over each subplot\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Define colors\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive']\n",
    "\n",
    "# Iterate over each column and plot it on a separate subplot\n",
    "for i, (col, color) in enumerate(zip(df.columns, colors)):\n",
    "    ax = axes[i]  # Get the current subplot\n",
    "    \n",
    "    # Plot the data\n",
    "    ax.plot(df.index, df[col], color=color, linestyle='-')\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(col)\n",
    "    ax.set_xlabel('date')\n",
    "    ax.set_ylabel(col)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Remove grid\n",
    "    ax.grid(False)\n",
    "\n",
    "# Adjust layout and show plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "##Create time series features based on time series index\n",
    "df=create_features(df)\n",
    "df\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Data spliting \n",
    "'''\n",
    "## split the data train data 80% (922), test data 20% (230)\n",
    "train=df.iloc[:-230]\n",
    "test=df.iloc[-230:]\n",
    "\n",
    "\n",
    "'''\n",
    "creating empty data frame to store the results \n",
    "'''\n",
    "\n",
    "# Define column names\n",
    "columns = ['Predicted calls Arima', 'Predicted sickness rate Arima', \n",
    "           'Predicted calls Prophet', 'Predicted sickness rate Prophet', \n",
    "           'Predicted calls XGboost', 'Predicted sickness rate XGboost']\n",
    "\n",
    "# Create an empty DataFrame with the specified column names\n",
    "results_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Assuming 'test' is your DataFrame containing the additional columns\n",
    "test_columns = ['dafted', 'sby_need', 'n_duty']\n",
    "\n",
    "# Add columns from 'test' DataFrame to the empty DataFrame\n",
    "for col in test_columns:\n",
    "    results_df[col] = test[col]\n",
    "\n",
    "# Set the index of the results_df to match the index of the test DataFrame\n",
    "results_df.index = test.index\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "results_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "ARIMA model function\n",
    "'''\n",
    "\n",
    "\n",
    "def arima_model(training_data, testing_data, order, results_df, predicted_column_name, plot_title):\n",
    "    \"\"\"\n",
    "    Apply ARIMA model to training data, test on testing data, and return evaluation metrics and visualization.\n",
    "    Add predicted values to the provided DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - training_data: pandas Series, training data for the ARIMA model\n",
    "    - testing_data: pandas Series, testing data for evaluating the ARIMA model\n",
    "    - order: tuple, order of the ARIMA model (p, d, q)\n",
    "    - results_df: pandas DataFrame, DataFrame to store the results\n",
    "    - predicted_column_name: str, name of the column to store the predicted values in the results_df\n",
    "    - plot_title: str, title of the plot\n",
    "\n",
    "    Returns:\n",
    "    - evaluation_metrics: dictionary, evaluation metrics including mean squared error, mean absolute error, and mean absolute percentage error\n",
    "    \"\"\"\n",
    "\n",
    "    # Fit ARIMA model\n",
    "    model = ARIMA(training_data, order=order)\n",
    "    fitted_model = model.fit()\n",
    "\n",
    "    # Forecast\n",
    "    predicted_values = fitted_model.forecast(steps=len(testing_data))\n",
    "\n",
    "    # Add predicted values to DataFrame\n",
    "    results_df[predicted_column_name] = predicted_values\n",
    "\n",
    "    # Evaluation metrics\n",
    "    mse = mean_squared_error(testing_data, predicted_values)\n",
    "    mae = mean_absolute_error(testing_data, predicted_values)\n",
    "    mape = np.mean(np.abs((testing_data - predicted_values) / testing_data)) * 100\n",
    "\n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(training_data, label='Training Data')\n",
    "    plt.plot(testing_data.index, testing_data, label='Actual Values')\n",
    "    plt.plot(testing_data.index, predicted_values, label='Predicted Values', color='red')\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Return results\n",
    "    evaluation_metrics = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'Mean Absolute Percentage Error': mape}\n",
    "    return evaluation_metrics\n",
    "\n",
    "\n",
    "'''\n",
    "make prediction using ARIMA model function \n",
    "'''\n",
    "# after Performing stepwise search to minimize aic the best order (2,1,1) \n",
    "arima_model(train['calls'], test['calls'], (2,1,1), results_df, 'Predicted calls Arima', 'Predicted calls Arima')\n",
    "\n",
    "\n",
    "'''\n",
    "make prediction using ARIMA model function \n",
    "'''\n",
    "# after Performing stepwise search to minimize aic the best order (1,1,1) \n",
    "arima_model(train['sickness rate'], test['sickness rate'], (1,1,1), results_df, 'Predicted sickness rate Arima', 'Predicted sickness rate Arima')\n",
    "\n",
    "'''\n",
    "create function for XGboost model\n",
    "'''\n",
    "\n",
    "def xgboost_model(training_data, testing_data, target_column, results_df, predicted_column_name, plot_title):\n",
    "    \"\"\"\n",
    "    Apply XGBoost model to training data, test on testing data, and add predicted values to results DataFrame.\n",
    "\n",
    "    Args:\n",
    "    - training_data: pandas DataFrame, training data for the XGBoost model with features and target variable\n",
    "    - testing_data: pandas DataFrame, testing data for evaluating the XGBoost model with features and target variable\n",
    "    - target_column: str, name of the target variable column\n",
    "    - results_df: pandas DataFrame, DataFrame to store the results\n",
    "    - predicted_column_name: str, name of the column to store the predicted values in the results_df\n",
    "    - plot_title: str, title of the plot\n",
    "\n",
    "    Returns:\n",
    "    - evaluation_metrics: dictionary, evaluation metrics including mean squared error, mean absolute error, and mean absolute percentage error\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract features and target variable from training data\n",
    "    X_train = training_data.drop(columns=[target_column])\n",
    "    y_train = training_data[target_column]\n",
    "\n",
    "    # Extract features and target variable from testing data\n",
    "    X_test = testing_data.drop(columns=[target_column])\n",
    "    y_test = testing_data[target_column]\n",
    "\n",
    "    # Initialize XGBoost regressor\n",
    "    reg = xgb.XGBRegressor(n_estimators=1000)\n",
    "\n",
    "    # Fit XGBoost model to training data\n",
    "    reg.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions on testing data\n",
    "    y_pred = reg.predict(X_test)\n",
    "\n",
    "    # Add predicted values to results DataFrame\n",
    "    results_df[predicted_column_name] = np.nan\n",
    "    results_df.iloc[-len(y_pred):, results_df.columns.get_loc(predicted_column_name)] = y_pred\n",
    "\n",
    "    # Plot actual, predicted, and training data\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot training data\n",
    "    plt.plot(training_data.index, training_data[target_column], color='#6E9ECF', label='Training Data')\n",
    "\n",
    "    # Plot testing data\n",
    "    plt.plot(testing_data.index, testing_data[target_column], color='orange', label='Testing Data')\n",
    "\n",
    "    # Plot predicted values\n",
    "    plt.plot(testing_data.index, y_pred, color='red', linestyle='--',label='Predicted Values')\n",
    "\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Target Variable')\n",
    "    plt.title(plot_title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "    # Return evaluation metrics\n",
    "    evaluation_metrics = {'Mean Squared Error': mse, 'Mean Absolute Error': mae, 'Mean Absolute Percentage Error': mape}\n",
    "    return evaluation_metrics, xgb.plot_importance(reg, title=target_column, xlabel='Feature Importance Score', ylabel='Features', grid=False)\n",
    "\n",
    "\n",
    "'''\n",
    "apply XGboost function to predict calls \n",
    "'''\n",
    "xgboost_model(train, test, 'calls', results_df, 'Predicted calls XGboost', 'Predicted calls XGboost')\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "apply XGboost function to predict sickness rate \n",
    "'''\n",
    "xgboost_model(train, test, 'sickness rate', results_df, 'Predicted sickness rate XGboost', 'Predicted sickness rate XGboost')\n",
    "\n",
    "\n",
    "'''\n",
    "preparing data for Prophet model \n",
    "\n",
    "'''\n",
    "\n",
    "#create new data frame for calls\n",
    "df_calls = df.reset_index()[[\"date\", \"calls\"]].rename(\n",
    "    columns={\"date\": \"ds\", \"calls\": \"y\"}\n",
    ")\n",
    "#splitting calls data into traing and testing data  \n",
    "train_calls=df_calls.iloc[:-230]\n",
    "test_calls=df_calls.iloc[-230:]\n",
    "\n",
    "#create new data frame for sickness rate\n",
    "df_sickness_rate = df.reset_index()[[\"date\", \"sickness rate\"]].rename(\n",
    "    columns={\"date\": \"ds\", \"sickness rate\": \"y\"}\n",
    ")\n",
    "#splitting sickness rate data into traing and testing data \n",
    "train_sickness_rate=df_sickness_rate.iloc[:-230]\n",
    "test_sickness_rate=df_sickness_rate.iloc[-230:]\n",
    "\n",
    "\n",
    "'''\n",
    "creating function for Prophet model\n",
    "'''\n",
    "\n",
    "def prophet_model(training_data, testing_data, results_df, predicted_column_name, plot_title):\n",
    "    # Initialize Prophet model\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    \n",
    "    # Fit the model using training data\n",
    "    model.fit(training_data)\n",
    "    \n",
    "    # Make future dataframe for testing data\n",
    "    future = model.make_future_dataframe(periods=len(testing_data))\n",
    "    \n",
    "    # Predict values for testing data\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Extract last 230 predicted values\n",
    "    predicted_values = forecast['yhat'].tail(230)\n",
    "    \n",
    "    # Add the last 230 predicted values to results_df\n",
    "    results_df[predicted_column_name] = predicted_values.values\n",
    "    \n",
    "    # Calculate evaluation metrics\n",
    "    mse = mean_squared_error(testing_data['y'], predicted_values)\n",
    "    mae = mean_absolute_error(testing_data['y'], predicted_values)\n",
    "    mape = np.mean(np.abs((testing_data['y'] - predicted_values) / testing_data['y'])) * 100\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"Evaluation Metrics:\")\n",
    "    print(\"Mean Squared Error (MSE):\", mse)\n",
    "    print(\"Mean Absolute Error (MAE):\", mae)\n",
    "    print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "    \n",
    "  \n",
    "    \n",
    "    # Plot forecast\n",
    "    model.plot(forecast, xlabel='Date', ylabel='Value')\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "predicting cals using prophet function\n",
    "'''\n",
    "prophet_model(train_calls, test_calls, results_df, 'Predicted calls Prophet', 'Calls Prediction with Prophet')\n",
    "\n",
    "\n",
    "'''\n",
    "predicting sickness rate using prophet function\n",
    "'''\n",
    "\n",
    "prophet_model(train_sickness_rate, test_sickness_rate, results_df, 'Predicted sickness rate Prophet', 'Predicted sickness rate Prophet')\n",
    "\n",
    "\n",
    "'''\n",
    "calculating Sby_drivers according to predicted values calls sickness rate\n",
    "n_sby=(n_calls/(AHC_target ))+n_duty (sickness rate-1)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "AHC_target=5\n",
    "\n",
    "results_df['Sby_xgboost']= (results_df['Predicted calls XGboost']/AHC_target)+results_df['n_duty']*(results_df['Predicted sickness rate XGboost']-1)\n",
    "results_df['Sby_xgboost'] = results_df['Sby_xgboost'].clip(lower=0)\n",
    "results_df['Sby_xgboost'] = results_df['Sby_xgboost'].round(0)\n",
    "results_df['dafted_Xgboost']=results_df['sby_need'] - results_df['Sby_xgboost']\n",
    "results_df['dafted_Xgboost']= results_df['dafted_Xgboost'].clip(lower=0)\n",
    "\n",
    "results_df['Sby_ARIMA']= (results_df['Predicted calls Arima']/AHC_target)+results_df['n_duty']*(results_df['Predicted sickness rate Arima']-1)\n",
    "results_df['Sby_ARIMA'] = results_df['Sby_ARIMA'].clip(lower=0)\n",
    "results_df['Sby_ARIMA'] = results_df['Sby_ARIMA'].round(0)\n",
    "results_df['dafted_ARIMA']=results_df['sby_need'] - results_df['Sby_ARIMA']\n",
    "results_df['dafted_ARIMA']= results_df['dafted_ARIMA'].clip(lower=0)\n",
    "\n",
    "\n",
    "results_df['Sby_Prophet']= (results_df['Predicted calls Prophet']/AHC_target)+results_df['n_duty']*(results_df['Predicted sickness rate Prophet']-1)\n",
    "results_df['Sby_Prophet'] = results_df['Sby_Prophet'].clip(lower=0)\n",
    "results_df['Sby_Prophet'] = results_df['Sby_Prophet'].round(0)\n",
    "results_df['dafted_Prophet']=results_df['sby_need'] - results_df['Sby_Prophet']\n",
    "results_df['dafted_Prophet']= results_df['dafted_Prophet'].clip(lower=0)\n",
    "\n",
    "\n",
    "'''\n",
    "Visiualizing dafted using predoction models vs dafted actual \n",
    "\n",
    "'''\n",
    "\n",
    "# Plotting dafted vs dafted_xgboost\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=results_df[['dafted', 'dafted_Xgboost']])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Actual dafted vs dafted_Xgboost')\n",
    "plt.legend(labels=['Actual dafted', 'dafted_Xgboost'])\n",
    "plt.show()\n",
    "\n",
    "# Plotting dafted vs dafted_arima\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=results_df[['dafted', 'dafted_ARIMA']])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('dafted vs dafted_ARIMA')\n",
    "plt.legend(labels=['Actual dafted', 'dafted_ARIMA'])\n",
    "plt.show()\n",
    "\n",
    "# Plotting dafted vs dafted_prophet\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=results_df[['dafted', 'dafted_Prophet']])\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Value')\n",
    "plt.title('dafted vs dafted_Prophet')\n",
    "plt.legend(labels=['Actual dafted', 'dafted_Prophet'])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "'''\n",
    "# Create histograms for the 'dafted' and 'dafted_Xgboost' columns\n",
    "'''\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "results_df['dafted'].plot(kind='hist', bins=20, color='blue', edgecolor='black')\n",
    "plt.title('Histogram of dafted')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "results_df['dafted_Xgboost'].plot(kind='hist', bins=20, color='green', edgecolor='black')\n",
    "plt.title('Histogram of dafted_Xgboost')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
